{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "import feather\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chromedriver = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup Function\n",
    "def selector_tools():\n",
    "    selector1 = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//*[@id=\"all_lineups-2-man\"]/div[1]/div'))\n",
    "            );\n",
    "    selector1.click()\n",
    "        \n",
    "    selector2 = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//*[@id=\"share_on_lineups-2-man\"]'))\n",
    "            );\n",
    "    selector2.click()\n",
    "        \n",
    "    selector3 = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//*[@id=\"commands_lineups-2-man\"]/div[4]/button[2]'))\n",
    "            );\n",
    "    selector3.click()\n",
    "        \n",
    "    selector4 = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//*[@id=\"share\"]/p/input'))\n",
    "            );\n",
    "    selector4.click()\n",
    "        \n",
    "    selector5 = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//*[@id=\"modal-content\"]/p[1]/strong/a'))\n",
    "            );\n",
    "    selector5.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def scrape_all_players(driver):\n",
    "    \n",
    "    main_url = 'http://www.basketball-reference.com/players/s/'\n",
    "    driver.get(main_url)\n",
    "    player_list_p = driver.find_elements_by_xpath('//th//a')\n",
    "    \n",
    "    def returnthis():\n",
    "        href = []\n",
    "        for item in player_list_p:\n",
    "            href.append(item.get_attribute('href').replace('.html', '/lineups/2016'))\n",
    "        return href\n",
    "    \n",
    "    for z in returnthis():\n",
    "        driver.get(z);\n",
    "\n",
    "        url = driver.current_url\n",
    "        response = requests.get(url)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page,\"lxml\")\n",
    "        \n",
    "        check_me = soup.findAll('tr')\n",
    "        \n",
    "        if check_me == []:\n",
    "            continue\n",
    "        else:\n",
    "            selector_tools()\n",
    "            url = driver.current_url\n",
    "            response = requests.get(url)\n",
    "            page = response.text\n",
    "            soup = BeautifulSoup(page,\"lxml\")\n",
    "            \n",
    "            table_headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
    "            data_rows = soup.findAll('tr')[2:]\n",
    "        \n",
    "            player_data = [[td.getText() for td in data_rows[i].findAll('td')] for i in range(len(data_rows))]\n",
    "            player_data_02 = []\n",
    "        \n",
    "            for i in range(len(data_rows)):\n",
    "                 player_row = []\n",
    "        \n",
    "            for td in data_rows[i].findAll('td'):        \n",
    "                player_row.append(td.getText())        \n",
    "        \n",
    "            player_data_02.append(player_row)\n",
    "            df = pd.DataFrame(player_data, columns=table_headers[1:])\n",
    "            df = df[:-1]\n",
    "            \n",
    "            playername = soup.find('h1').getText()\n",
    "            playername = playername.split(' 2')[0]\n",
    "            df['playername'] = playername\n",
    "            if os.path.isfile('my_2016nbafile18.feather') == False:\n",
    "                path = 'my_2016nbafile18.feather'\n",
    "                feather.write_dataframe(df, path)\n",
    "            else:\n",
    "                ogdf = feather.read_dataframe('my_2016nbafile18.feather')\n",
    "                df = ogdf.append(df, ignore_index=True)\n",
    "                path = 'my_2016nbafile18.feather'\n",
    "                feather.write_dataframe(df, path)\n",
    "        \n",
    "                \n",
    "scrape_all_players(driver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
